---
title: "MSU Grade Analysis"
author: "Adhi Rajaprabhakaran"
date: "9/19/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(tibble.print_max = 15, tibble.print_min = 15)
```

## Importing/Cleaning

Firstly, I just wanna give huge, huge props to Colin Dillinger who is the one who submitted the FOIA and scraped all the data into the excel format that we're about to download. It's just that excel isn't good enough for me :).

Let's download and check out the dataset as it is.

```{r cars}
library(tidyverse)

httr::GET("https://msugrades.github.io/excel/Grades.xlsx", httr::write_disk(tf <- tempfile(fileext = ".xlsx")))
grades <- readxl::read_excel(tf)

glimpse(grades)
```

So we can see that we have about 36k rows and 43 columns, where each row is a class-semester-professor combination, and each column is some information about it.

The FOIA office was kind enough to calculate mean grades for us, but we will calculate it ourselves after tidying the data a bit.

There are two grading scales in this dataset - the point scale and the letter scale. The vast majority of MSU students are graded on the point scale, 1.0-4.0. The one exception is the law school, where a more traditional letter scale is used. Just to make sure:

```{r}
grades %>% 
  filter(`A` > 0) %>% 
  select(`Subject Code`) %>% 
  unique()
```
These data are interesting in their own right, but let's just look at grades that abide by the regular system. 

```{r deselect law data}
grades <- grades %>%
  filter(`Subject Code` != 'LAW') %>%
  select( -8, -(26:38)) # these columns are the law school grades, we don't want them

glimpse(grades)
```

The dataset has some annoying column names, with spaces and capital letters. I heard what's cool in the tidyverse is all lowercase and underscores in lieu of spaces.

```{r rename cols}
names(grades) <- names(grades) %>% 
  tolower() %>% 
  gsub(" ", "_", .)
names(grades)
```

Now, as a devotee of the tidyverse (Praise Be Upon Hadley), I have to convert this data to tidy format, even if I get a dataframe with unwieldly dimensions.

In the process, I drop all of the columns that don't give us grade information. I'm sure there are interesting questions to ask regarding incompletes and auditors, but that's for another day as we're trying to establish a mile-high look at grading practices most relevant to studennts.

```{r tidy data}
tidy_grades <- grades %>%
  select(term_code:instructor, `4`:`0`) %>%
  gather(grade, quantity, -(term_code:instructor)) %>%
  mutate(grade = as.numeric(grade),
         course_code = as.numeric(course_code)) #numerics are easier to sort by

glimpse(tidy_grades)
```

Now we have a tidy dataset that is a whopping 360k rows and 8 columns. Every row is a professor-class-semester-grade combination, and the observation is the quantity of the grade awarded. 

The one hold up is that there are nearly 200 unique subject codes and we don't know all of them. To find out, let's join that in really quick by scraping it off MSU's class schedule site.

```{r scraping major names}
library("rvest")

codes_and_names <- read_html("https://schedule.msu.edu/") %>%
  #the following is the html tag to access a dropdown with all majors
  html_nodes("#MainContent_SrearchUC_ddlSubject option") %>%
  html_text() %>%
  str_split(":", simplify = TRUE) %>%
  as_tibble() %>%
  rename(subject_code = V1,
         subject_name = V2)

codes_and_names
```
```{r}
tidy_grades <- tidy_grades %>%
  left_join(codes_and_names) %>%
  #reordering the columns
  select(term_code:subject_code, subject_name, course_code:quantity) 

glimpse(tidy_grades)
```

Now, let's get to the good parts.

## Which majors are the easiest and hardest?

This is naturally the first question that a student would be interested in knowing. 

Due the format of the grade information, we have to get a bit creative with calculating the summary stats of each subject by using `sum` and `rep` for the mean and median grade respsectively.
```{r}
gpas_by_subject <- tidy_grades %>%
  group_by(subject_code, subject_name) %>%
  #reasonable amount of students since 2011 to lose outliers
  #filter(sum(quantity) > 5000) %>% 
  summarise(mean_grade = sum(grade*quantity)/sum(quantity),
            median_grade = median(rep(grade, quantity), na.rm = TRUE),
            freq = sum(quantity))
            #this will be the number of grades awarded in total sicne 2017

gpas_by_subject
```

Easiest majors:
```{r easiest majors}
gpas_by_subject %>%
  arrange(desc(mean_grade))
```
Hardest majors:
```{r hardest majors}
gpas_by_subject %>%
  arrange(mean_grade)
```

I noticed that the easier subjects have very little grades awarded, and the opposite is true for hte harder subjects. We can investigate that with a scatterplot. Due to the long tailed nature of the frequencies, I log-transformed `freq`.

``` {r grade vs quant scatter}
gpas_by_subject %>%
  ggplot(aes(log(freq), mean_grade)) +
  geom_point() +
  geom_smooth(method = 'lm')
```

We can see a clear negative relationship between the quantity of students and the average grade awarded.

```{r distribution of university}
tidy_grades %>%
  group_by(grade) %>%
  summarise(freq = sum(quantity)) %>%
  ggplot(aes(grade, freq)) +
  geom_histogram(stat = "identity") +
  ggtitle("Grades awarded at MSU since 2011")
```

## Trends over time

### Grade inflation
```{r subject over time}
tidy_grades_semester <- tidy_grades %>%
  # using rank to get the positional order of every semester)
  mutate(semester = dense_rank(tidy_grades$sortable_term)) %>%
  group_by(subject_code, semester) %>%
  summarise(mean_grade = sum(grade*quantity)/sum(quantity))
```

```{r}
tidy_grades %>%
  # using rank to get the positional order of every semester)
  mutate(semester = dense_rank(tidy_grades$sortable_term)) %>%
  group_by(semester) %>%
  summarise(mean_grade = sum(grade*quantity)/sum(quantity)) %>%
  ggplot(aes(semester, mean_grade)) +
  geom_line()
```

Two things - clear grade inflation and seasonaility at MSU. The peaks are summer semesters, which isn't surprising. A lot of "fluff" or "blow off" classes are offered online over the summer. What I do find interesting is that spring (Jan - May) semesters tend to be consistently easier than fall semesters (Aug - Dec). Let's split this up by season.

```{r}
tidy_grades_season <- tidy_grades %>%
  # using rank to get the positional order of every semester)
  mutate(semester = dense_rank(tidy_grades$sortable_term),
         season = str_sub(term_code, 1,1),
         season = ifelse(season == "F", "Fall",
                         ifelse(season == "S", "Spring",
                                ifelse(season == "U", "Summer", NA))
                         )
         )

tidy_grades_season %>%
  group_by(semester, season) %>%
  summarise(mean_grade = sum(grade*quantity)/sum(quantity)) %>%
  ggplot(aes(semester, mean_grade, color = season)) +
  geom_point() +
  geom_line()
```

Which subjects specifically inflated more or less than the others? Here, I'm going to use a clever modeling pattern I learned from David Robinson's EDA course on datacamp. Basically, I split all the data into mini-datasets by semester and subject, then fit a linear model to each mini-dataset, and then extract the coefficients. It's fucking awesome.

```{r}
library("broom")

by_semester_subject <- tidy_grades_season %>%
  group_by(semester, subject_code, subject_name) %>%
  summarise(mean_grade = sum(grade*quantity)/sum(quantity))

sem_sub_slopes <- by_semester_subject %>%
  ungroup() %>%
  filter(!is.na(mean_grade)) %>%
  nest(-subject_code, -subject_name) %>%
  mutate(models = map(data, ~ lm(mean_grade ~ semester, .))) %>%
  mutate(tidied = map(models, tidy)) %>%
  unnest(tidied)

sem_sub_slopes
```
Most inflated
```{r}
sem_sub_slopes %>%
  filter(term == "semester") %>%
  arrange(desc(estimate))
```
Most tom-brady-ed
```{r}
sem_sub_slopes %>%
  filter(term == "semester") %>%
  arrange(estimate)
```

```{r}
tidy_grades %>%
  filter(subject_code %in% c("SCM", "FI", "ACC", "MKT", "HR", "MGT"),
         course_code < 500) %>%
  group_by(subject_code, course_code) %>%
  summarise(mean_grade = sum(grade*quantity)/sum(quantity),
            median_grade = median(rep(grade, quantity))) %>%
  arrange(-mean_grade)
```

```{r}
tidy_grades %>%
  filter(subject_code %in% c("SCM", "FI", "ACC", "MKT", "HR", "MGT"),
         course_code < 500) %>%
  group_by(subject_code, course_code) %>%
  summarise(mean_grade = sum(grade*quantity)/sum(quantity),
            median_grade = median(rep(grade, quantity))) %>%
  arrange(mean_grade)
```

